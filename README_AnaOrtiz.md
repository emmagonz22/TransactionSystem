# Venmito Data Engineering Project

Overview:

To complete the Venmito Data Engineering Project, I used Power BI for all the steps. I used this tool because of its data visualization options, the ability to integrate with multiple data sources, real-time data analysis, ability to collaborate and share, and because of its scalability. This also includes a super user-friendly platform and interface that works for technical and non-technical users. Another key component is the ability to accept data from different types of files and the ability to create relationships between tables.

My solution consists of a Power BI dashboard that can be accessed locally on one's computer or via a link: https://app.powerbi.com/view?r=eyJrIjoiNWU0ZDNlNTgtODgxMS00NDkwLWE0NjYtNjhjZjMzY2Q2NTMyIiwidCI6IjBkZmE1ZGMwLTAzNmYtNDYxNS05OWU0LTk0YWY4MjJmMmI4NCIsImMiOjF9

As part of my solution, I include a Venmito-AnaOrtiz zip folder and a README_AnaOrtiz. After extracting, the Venmito-AnaOrtiz.pbix (Source of data storing, transformation, and dashboard creation), data folder, and a PDF version of the dashboard that Power BI generates. I recommend accessing Power BI online or downloading Power BI desktop to fully see how the dashboard works and how the data was transformed, organized, and what relationships were created between them. After downloading, open the .pbit file. It should initially load the tables and start presenting the dashboard with the warnings about missing information because of the file paths that are linked to my local computer. To fix this, select "Transform Data" in the Home tab and this should open the Power Query. In the left, you will see different tables and a parameter called 'DataFolderPath'. This parameter acts as a variable for the location of the files. For example, C:\...\Desktop\Venmito-AnaOrtiz\ should be changed to the path on the local computer. This additional step is needed for the data to load correctly locally. The dashboard in the link will always work. Also, after selecting a table, on the right side you may see the transformations applied to the table. 

1. **Data Ingestion**: Power BI can read and load data from all the provided files. Natively, it accepts .XML, .JSON, and .CSV. For the .YAML file, Power BI does not handle it natively. Nonetheless, the user can manually input examples of how the data should be extracted using the "Example-based Extraction option" that uses machine learning algorithms to understand a pattern or logic behind the data extraction. With this transformation, I was able to generate 5 row/column tables based on the files given.

2. **Data Matching and Conforming**: Power BI also incorporates the ability to store and transform the data given. It also permits connecting to an Excel file or database to obtain information. In this case, given that the amount of data was low I used Power BI to store the data. Nonetheless, if the amount of data was much bigger I would store it in a database. After loading the data, I transformed and united the people.json and people.yaml under the same table People. I also changed the names of some of the columns and created relationships between the entities. 

3. **Data Analysis**: As part of the data analysis, I created four pages: 
                    1. Homepage - responsible of showing a summary and agglomeration of important data points. It displays the number of transfers completed, the total amount of money sent via transfers, total amount of money spent via transactions, number of customers, and number of items sold. It also displays three graphs and one table. One graph depicts the sales performance per store, the other one shows the units sold per item, and the final graph shows the promotion response rates. Finally, it portrays a table of the people who responded No to the promotion followed by the people who responded Yes. 
                    2. People Insights - responsible for showing the demographic distribution of people per cities and per countries and displays the device preferences. It also shows the number of cities, countries, and the number of customers.
                    3. Transactions Insights - responsible for showing a graph of transactions over time as well as profits over time in transactions. It also displays the total profit generated, total items bought, most bought item, and most visited store. It also includes two tables, one displaying the number of visits per store and another one showing the number of sales by item.
                    4. Transfer Insights - responsible for showing the amount of money in transfers over time and the number of transfers over time. It also displays the total amount in transfers, the number of transfers, the top sender, and the top receiver. It also includes a top senderâ€™s table portraying the top senders based on the quantity sent.

4. **Data Output**: The data output of this project is the Power BI dashboard that has 4 pages and displays data in different formats. The displays are interactive therefore, they may be filtered by clicking on them.

5. **Code**: In this project, I used Power BI for all the requirements. Why have different connections via different programs when you can do it all in one? My focus for this project was keeping it simple and straightforward, which the clients often want. Given other contexts, as in, more data or other requirements then other options would have been needed. In this case, I thought it was best not to complicate myself and the client. Necessary to mention that using Power BI provides a basically codeless approach and solution to the problem. Nonetheless, in the Power Query in Power BI, where data is loaded and transformed, an 'Advanced Editor' option is available that permits to use Power Query M formula language to code. 